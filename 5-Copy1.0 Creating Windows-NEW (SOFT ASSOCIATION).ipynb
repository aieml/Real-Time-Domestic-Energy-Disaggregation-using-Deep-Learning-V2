{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path='data/APPENDED'\n",
    "data_path='data'\n",
    "ref_dataset= np.load(os.path.join(path,'refrigerator.dat.npy'))\n",
    "print(ref_dataset[0])\n",
    "ref_bins=4\n",
    "ref_window_size=2401\n",
    "input_shape=(2401, 1)\n",
    "\n",
    "ref_dataset=ref_dataset[:,1:]\n",
    "print(ref_dataset.shape)\n",
    "\n",
    "bin_max_count=[0 for i in range(ref_bins)]\n",
    "ref_clusters=[6.64953227,193.52627165,456.50688195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "def load_cnn():\n",
    "    \n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters=8,kernel_size=5,input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=8,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=8,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Conv1D(filters=16,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=16,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=16,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Conv1D(filters=32,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=32,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=32,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Conv1D(filters=64,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=64,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=64,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3,activation='sigmoid'))\n",
    "\n",
    "    from keras.optimizers import Adam\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    decay_rate = 2\n",
    "    momentum = 0.8\n",
    "    opt= Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=decay_rate)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import normalize\n",
    "\n",
    "bin_dict=collections.Counter(ref_dataset[:,1])\n",
    "\n",
    "ref_data=[]\n",
    "ref_target=[]\n",
    "\n",
    "model=load_cnn()\n",
    "k=0\n",
    "count=0\n",
    "graph_no=0\n",
    "key_min = min(bin_dict.keys(), key=(lambda k: bin_dict[k]))\n",
    "ref_min_bin=bin_dict[key_min]\n",
    "print(ref_min_bin)\n",
    "\n",
    "epo=0\n",
    "while(epo<10):\n",
    "\n",
    "    for i in range(ref_dataset.shape[0]-ref_window_size-1-200000):\n",
    "        ref_data.append(ref_dataset[i:i+ref_window_size,0])\n",
    "\n",
    "        appliance=ref_dataset[i+ref_window_size-1,1]\n",
    "        #print(appliance)\n",
    "\n",
    "        total=np.sum(np.array([1/np.power(ref_clusters[j]-appliance,2) for j in range (len(ref_clusters))]))\n",
    "        prob0=(1/np.power(ref_clusters[0]-appliance,2))/total\n",
    "        prob1=(1/np.power(ref_clusters[1]-appliance,2))/total\n",
    "        prob2=(1/np.power(ref_clusters[2]-appliance,2))/total\n",
    "        #prob3=(1/np.power(ref_clusters[3]-appliance[i],2))/total    \n",
    "        #print(appliance,[prob0,prob1,prob2],np.sum([prob0*[ref_clusters[0]],prob1*[ref_clusters[1]],prob2*[ref_clusters[2]]]))\n",
    "        ref_target.append([prob0,prob1,prob2])\n",
    "\n",
    "data=np.array(ref_data)/500.0\n",
    "data = normalize(data, axis=1)\n",
    "target=np.array(ref_target)\n",
    "data=data.reshape(data.shape[0],data.shape[1],1)\n",
    "print(target.shape,target[0])\n",
    "\n",
    "\n",
    "history=model.fit(data[:data.shape[0]-100000,:],target[:data.shape[0]-100000,:],epochs=1) \n",
    "\n",
    "ref_data=[]\n",
    "ref_target=[]\n",
    "k=0\n",
    "count=count+1\n",
    "\n",
    "\n",
    "    #            ref_data=[]\n",
    "    #            ref_target=[]        \n",
    "    #            for i in range(10000):\n",
    "    #                ref_data.append(ref_dataset[700000+i:700000+i+ref_window_size,0])\n",
    "\n",
    "    #                appliance=ref_dataset[700000+i+ref_window_size-1,1]\n",
    "                    #print(appliance)\n",
    "\n",
    "    #                total=np.sum(np.array([1/np.power(ref_clusters[j]-appliance,2) for j in range (len(ref_clusters))]))\n",
    "    #                prob0=(1/np.power(ref_clusters[0]-appliance,2))/total\n",
    "    #                prob1=(1/np.power(ref_clusters[1]-appliance,2))/total\n",
    "    #                prob2=(1/np.power(ref_clusters[2]-appliance,2))/total\n",
    "                    #prob3=(1/np.power(ref_clusters[3]-appliance[i],2))/total    \n",
    "                    #print(appliance,[prob0,prob1,prob2],np.sum([prob0*[ref_clusters[0]],prob1*[ref_clusters[1]],prob2*[ref_clusters[2]]]))\n",
    "\n",
    "    #                ref_target.append([prob0,prob1,prob2])\n",
    "\n",
    "    #            data=np.array(ref_data)/500.0\n",
    "    #            data = normalize(data, axis=1)\n",
    "    #            target=np.array(ref_target)\n",
    "    #            data=data.reshape(data.shape[0],data.shape[1],1)\n",
    "\n",
    "print(model.evaluate(data[data.shape[0]-100000:,:],target[data.shape[0]-100000:,:]))\n",
    "results=model.predict(data[data.shape[0]-100000:,:])\n",
    "plt.plot(np.argmax(target[data.shape[0]-100000:,:],axis=1),'b',label='ACTUAL')\n",
    "plt.plot(np.argmax(results,axis=1),'r--',label='PREDICTED')\n",
    "plt.legend()\n",
    "plt.savefig('graphs_soft_association/'+str(epo)+str(graph_no)+'.jpg')\n",
    "plt.close()\n",
    "\n",
    "ref_data=[]\n",
    "ref_target=[]\n",
    "k=0\n",
    "count=0\n",
    "graph_no=graph_no+1\n",
    "epo=epo+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(test_target,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(test_target,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
