{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "import keras\n",
    "\n",
    "logs_base_dir=\"logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir logs2 (started 2 days, 21:00:28 ago; pid 4940)\n",
      "  - port 6006: logdir logs (started 2 days, 21:42:38 ago; pid 9348)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.30313293e+09 2.22200000e+02 6.00000000e+00]\n",
      "(1575991, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path='data/APPENDED'\n",
    "data_path='data'\n",
    "ref_dataset= np.load(os.path.join(path,'refrigerator.dat.npy'))\n",
    "print(ref_dataset[0])\n",
    "ref_bins=4\n",
    "ref_window_size=2401\n",
    "input_shape=(2401, 1)\n",
    "\n",
    "ref_dataset=ref_dataset[:,1:]\n",
    "print(ref_dataset.shape)\n",
    "\n",
    "bin_max_count=[0 for i in range(ref_bins)]\n",
    "ref_clusters=[6.64953227,193.52627165,456.50688195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout,Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import normalize\n",
    "from keras.layers import BatchNormalization,Concatenate\n",
    "from keras import Input\n",
    "input_shape=(2401, 1)\n",
    "\n",
    "def load_cnn():\n",
    "    \n",
    "    input_shape=(2401, 1)\n",
    "    inp=Input(shape=input_shape)\n",
    "    convs=[]\n",
    "\n",
    "    parrallel_kernels=[3,5,7]\n",
    "\n",
    "    for k in range(len(parrallel_kernels)):\n",
    "\n",
    "        conv = Conv1D(3, parrallel_kernels[k],border_mode='same',activation='linear',input_shape=input_shape,strides=1)(inp)\n",
    "        convs.append(conv)\n",
    "\n",
    "    out = Concatenate()(convs)\n",
    "    conv_model = Model(input=inp, output=out)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(conv_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128,input_dim=128,activation='relu'))\n",
    "    model.add(Dense(3,input_dim=128,activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(3, 3, activation=\"linear\", input_shape=(2401, 1), strides=1, padding=\"same\")`\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(3, 5, activation=\"linear\", input_shape=(2401, 1), strides=1, padding=\"same\")`\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(3, 7, activation=\"linear\", input_shape=(2401, 1), strides=1, padding=\"same\")`\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.1238 - accuracy: 0.9501\n",
      "Epoch 2/15\n",
      "250000/250000 [==============================] - 282s 1ms/step - loss: 0.0742 - accuracy: 0.9714\n",
      "Epoch 3/15\n",
      "250000/250000 [==============================] - 288s 1ms/step - loss: 0.0568 - accuracy: 0.9809\n",
      "Epoch 4/15\n",
      "250000/250000 [==============================] - 289s 1ms/step - loss: 0.0498 - accuracy: 0.9845\n",
      "Epoch 5/15\n",
      "250000/250000 [==============================] - 286s 1ms/step - loss: 0.0459 - accuracy: 0.9862\n",
      "Epoch 6/15\n",
      "250000/250000 [==============================] - 288s 1ms/step - loss: 0.0428 - accuracy: 0.9874\n",
      "Epoch 7/15\n",
      "250000/250000 [==============================] - 291s 1ms/step - loss: 0.0403 - accuracy: 0.9888\n",
      "Epoch 8/15\n",
      "250000/250000 [==============================] - 291s 1ms/step - loss: 0.0371 - accuracy: 0.9901\n",
      "Epoch 9/15\n",
      "250000/250000 [==============================] - 284s 1ms/step - loss: 0.0357 - accuracy: 0.9909\n",
      "Epoch 10/15\n",
      "250000/250000 [==============================] - 282s 1ms/step - loss: 0.0347 - accuracy: 0.9914\n",
      "Epoch 11/15\n",
      "250000/250000 [==============================] - 290s 1ms/step - loss: 0.0333 - accuracy: 0.9918\n",
      "Epoch 12/15\n",
      "250000/250000 [==============================] - 284s 1ms/step - loss: 0.0332 - accuracy: 0.9917\n",
      "Epoch 13/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.0320 - accuracy: 0.9921\n",
      "Epoch 14/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.0318 - accuracy: 0.9924\n",
      "Epoch 15/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.0311 - accuracy: 0.9924\n",
      "250000/250000 [==============================] - 69s 276us/step\n",
      "[0.5008830949410465, 0.9340400099754333] 0 0\n",
      "==========================window 249704-252105==========================\n",
      "TP: 51225 FP: 7357 TN: 184104 FN: 7314 P: 58539 N: 191461\n",
      "Recall: 87.50576538717777 Precision: 87.4415349424738 Accuaracy: 94.1316 F1: 87.47363837398929\n",
      "Epoch 1/15\n",
      "250000/250000 [==============================] - 283s 1ms/step - loss: 0.1463 - accuracy: 0.9445\n",
      "Epoch 2/15\n",
      "250000/250000 [==============================] - 280s 1ms/step - loss: 0.1002 - accuracy: 0.9641\n",
      "Epoch 3/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.0855 - accuracy: 0.9709\n",
      "Epoch 4/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.0790 - accuracy: 0.9736\n",
      "Epoch 5/15\n",
      "250000/250000 [==============================] - 279s 1ms/step - loss: 0.0729 - accuracy: 0.9761\n",
      "Epoch 6/15\n",
      "250000/250000 [==============================] - 279s 1ms/step - loss: 0.0698 - accuracy: 0.9781\n",
      "Epoch 7/15\n",
      "250000/250000 [==============================] - 280s 1ms/step - loss: 0.0671 - accuracy: 0.9791\n",
      "Epoch 8/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.0657 - accuracy: 0.9798\n",
      "Epoch 9/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.0640 - accuracy: 0.9802\n",
      "Epoch 10/15\n",
      "250000/250000 [==============================] - 278s 1ms/step - loss: 0.0628 - accuracy: 0.9809\n",
      "Epoch 11/15\n",
      "250000/250000 [==============================] - 281s 1ms/step - loss: 0.0610 - accuracy: 0.9819\n",
      "Epoch 12/15\n",
      "250000/250000 [==============================] - 280s 1ms/step - loss: 0.0603 - accuracy: 0.9819\n",
      "Epoch 13/15\n",
      "250000/250000 [==============================] - 277s 1ms/step - loss: 0.0602 - accuracy: 0.9820\n",
      "Epoch 14/15\n",
      "250000/250000 [==============================] - 282s 1ms/step - loss: 0.0574 - accuracy: 0.9831\n",
      "Epoch 15/15\n",
      "250000/250000 [==============================] - 285s 1ms/step - loss: 0.0564 - accuracy: 0.9836\n",
      "250000/250000 [==============================] - 70s 280us/step\n",
      "[0.4129292321774466, 0.9263120293617249] 0 1\n",
      "==========================window 249704-252105==========================\n",
      "TP: 54595 FP: 10170 TN: 178860 FN: 6375 P: 60970 N: 189030\n",
      "Recall: 89.54403805150073 Precision: 84.29707403690266 Accuaracy: 93.382 F1: 86.84137272835726\n",
      "Epoch 1/15\n",
      "250000/250000 [==============================] - 284s 1ms/step - loss: 0.0601 - accuracy: 0.9811\n",
      "Epoch 2/15\n",
      " 93248/250000 [==========>...................] - ETA: 2:58 - loss: 0.0471 - accuracy: 0.9859"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f85750a9c139>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mtensorboard_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mmc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weights/weights{epoch:08d}.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[1;31m#for layer in model.layers:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import normalize\n",
    "import csv\n",
    "\n",
    "\n",
    "bin_dict=collections.Counter(ref_dataset[:,1])\n",
    "\n",
    "ref_data=[]\n",
    "ref_target=[]\n",
    "\n",
    "model=load_cnn()\n",
    "\n",
    "\n",
    "k=0\n",
    "count=0\n",
    "graph_no=0\n",
    "key_min = min(bin_dict.keys(), key=(lambda k: bin_dict[k]))\n",
    "ref_min_bin=bin_dict[key_min]\n",
    "print(ref_min_bin)\n",
    "\n",
    "epo=0\n",
    "while(epo<1):\n",
    "    graph_no=0\n",
    "    for i in range(ref_dataset.shape[0]-ref_window_size-1-200000):\n",
    "        ref_data.append(ref_dataset[i:i+ref_window_size,0])\n",
    "\n",
    "        appliance=ref_dataset[i+ref_window_size-1,1]\n",
    "        #print(appliance)\n",
    "\n",
    "        total=np.sum(np.array([1/np.power(ref_clusters[j]-appliance,2) for j in range (len(ref_clusters))]))\n",
    "        prob0=(1/np.power(ref_clusters[0]-appliance,2))/total\n",
    "        prob1=(1/np.power(ref_clusters[1]-appliance,2))/total\n",
    "        prob2=(1/np.power(ref_clusters[2]-appliance,2))/total\n",
    "        #prob3=(1/np.power(ref_clusters[3]-appliance[i],2))/total    \n",
    "        #print(appliance,[prob0,prob1,prob2],np.sum([prob0*[ref_clusters[0]],prob1*[ref_clusters[1]],prob2*[ref_clusters[2]]]))\n",
    "        ref_target.append([prob0,prob1,prob2])\n",
    "        k=k+1\n",
    "        if(k==250000):\n",
    "            data=np.array(ref_data)/500.0\n",
    "            data = normalize(data, axis=1)\n",
    "            target=np.array(ref_target)\n",
    "            data=data.reshape(data.shape[0],data.shape[1],1)\n",
    "            #print(target.shape,data[0],target[0])\n",
    "\n",
    "            if(count!=1):\n",
    "                logdir = os.path.join(logs_base_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "                tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "                mc = keras.callbacks.ModelCheckpoint('weights/weights{epoch:08d}.h5', save_weights_only=True)\n",
    "                history=model.fit(data,target,epochs=15,callbacks=[mc]) \n",
    "                \n",
    "                #for layer in model.layers:\n",
    "                #    weights = layer.get_weights()\n",
    "                #    print(weights)\n",
    "                ref_data=[]\n",
    "                ref_target=[]\n",
    "                k=0\n",
    "                count=count+1\n",
    "\n",
    "            else:\n",
    "    #            ref_data=[]\n",
    "    #            ref_target=[]        \n",
    "    #            for i in range(10000):\n",
    "    #                ref_data.append(ref_dataset[700000+i:700000+i+ref_window_size,0])\n",
    "\n",
    "    #                appliance=ref_dataset[700000+i+ref_window_size-1,1]\n",
    "                    #print(appliance)\n",
    "\n",
    "    #                total=np.sum(np.array([1/np.power(ref_clusters[j]-appliance,2) for j in range (len(ref_clusters))]))\n",
    "    #                prob0=(1/np.power(ref_clusters[0]-appliance,2))/total\n",
    "    #                prob1=(1/np.power(ref_clusters[1]-appliance,2))/total\n",
    "    #                prob2=(1/np.power(ref_clusters[2]-appliance,2))/total\n",
    "                    #prob3=(1/np.power(ref_clusters[3]-appliance[i],2))/total    \n",
    "                    #print(appliance,[prob0,prob1,prob2],np.sum([prob0*[ref_clusters[0]],prob1*[ref_clusters[1]],prob2*[ref_clusters[2]]]))\n",
    "\n",
    "    #                ref_target.append([prob0,prob1,prob2])\n",
    "\n",
    "    #            data=np.array(ref_data)/500.0\n",
    "    #            data = normalize(data, axis=1)\n",
    "    #            target=np.array(ref_target)\n",
    "    #            data=data.reshape(data.shape[0],data.shape[1],1)\n",
    "\n",
    "                \n",
    "                print(model.evaluate(data,target),epo,graph_no)\n",
    "                results=model.predict(data)\n",
    "                \n",
    "                for i in range(0,results.shape[0],ref_window_size):\n",
    "                \n",
    "                    plt.plot(np.argmax(target[i:i+ref_window_size],axis=1),'b',label='ACTUAL')\n",
    "                    plt.plot(np.argmax(results[i:i+ref_window_size],axis=1),'r--',label='PREDICTED')\n",
    "                    plt.legend()\n",
    "                    plt.savefig('graphs_soft_association/parallel_CNN/'+str(epo)+str(graph_no)+str(i)+'.jpg')\n",
    "                    plt.close()\n",
    "\n",
    "                ref_data=[]\n",
    "                ref_target=[]\n",
    "                k=0\n",
    "                count=0\n",
    "                graph_no=graph_no+1\n",
    "                \n",
    "                #print(target.shape)\n",
    "                #print(results.shape)\n",
    "                actual=np.argmax(target,axis=1)\n",
    "                predicted=np.argmax(results,axis=1)\n",
    "                \n",
    "                tp=actual[predicted>0]\n",
    "                tp_count=len(np.where(tp>0)[0])\n",
    "                fp_count=len(np.where(tp==0)[0])\n",
    "                \n",
    "                tn=actual[predicted==0]\n",
    "                tn_count=len(np.where(tn==0)[0])\n",
    "                fn_count=len(np.where(tn>0)[0])\n",
    "                \n",
    "                p=len(np.where(actual>0)[0])\n",
    "                n=len(np.where(actual==0)[0])\n",
    "                try:\n",
    "                    recall=tp_count/(tp_count+fn_count)*100\n",
    "                    precision=tp_count/(tp_count+fp_count)*100\n",
    "                    accuracy=(tp_count+tn_count)/(p+n)*100\n",
    "                    f1=2*(precision*recall)/(precision+recall)\n",
    "                \n",
    "                    print(\"==========================window \"+str(i)+\"-\"+str(i+ref_window_size)+\"==========================\")\n",
    "                    print(\"TP:\",tp_count,\"FP:\",fp_count,\"TN:\",tn_count,\"FN:\",fn_count,\"P:\",p,\"N:\",n)\n",
    "                    print('Recall:',recall,\"Precision:\",precision,\"Accuaracy:\",accuracy,\"F1:\",f1)\n",
    "                except:\n",
    "                    pass\n",
    "    epo=epo+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
